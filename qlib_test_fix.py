#!/usr/bin/env python
"""
qlib_test.py ä¿®å¤ç‰ˆæœ¬
è§£å†³æ¨¡å—å¯¼å…¥è·¯å¾„é—®é¢˜
"""
import argparse
from collections import defaultdict
import os
import pickle
import sys

# ä¿®å¤Pythonè·¯å¾„é—®é¢˜
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
finetune_dir = os.path.join(project_root, 'finetune')

# æ·»åŠ å¿…è¦çš„è·¯å¾„åˆ°Pythonè·¯å¾„
sys.path.insert(0, project_root)  # é¡¹ç›®æ ¹ç›®å½•
sys.path.insert(0, finetune_dir)  # finetuneç›®å½•

print(f"âœ… é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"âœ… å½“å‰ç›®å½•: {current_dir}")
print(f"âœ… Pythonè·¯å¾„å·²ä¿®å¤")

from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
import torch
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

# æ£€æŸ¥å¹¶å¯¼å…¥qlibç›¸å…³æ¨¡å—
try:
    import qlib
    from qlib.backtest import backtest, executor
    from qlib.config import REG_CN
    from qlib.contrib.evaluate import risk_analysis
    from qlib.contrib.strategy import TopkDropoutStrategy
    from qlib.utils.time import Freq
    print("âœ… qlibæ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ qlibæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ’¡ è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…qlib")

# å¯¼å…¥é…ç½®
try:
    from config import Config
    print("âœ… é…ç½®æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ é…ç½®æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

# å¯¼å…¥Kronosæ¨¡å‹
try:
    from model.kronos import Kronos, KronosTokenizer, auto_regressive_inference
    print("âœ… Kronosæ¨¡å‹æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ Kronosæ¨¡å‹æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ’¡ å°è¯•ç›¸å¯¹å¯¼å…¥...")
    try:
        # å°è¯•ä»é¡¹ç›®æ ¹ç›®å½•å¯¼å…¥
        sys.path.append(os.path.join(project_root, 'model'))
        import kronos
        from kronos import Kronos, KronosTokenizer, auto_regressive_inference
        print("âœ… ä½¿ç”¨ç›¸å¯¹å¯¼å…¥æˆåŠŸ")
    except ImportError as e2:
        print(f"âŒ ç›¸å¯¹å¯¼å…¥ä¹Ÿå¤±è´¥: {e2}")
        sys.exit(1)

# =================================================================================
# 1. Data Loading and Processing for Inference
# =================================================================================

class QlibInferenceDataset(Dataset):
    """Dataset for inference on Qlib data."""
    
    def __init__(self, data, lookback_window, predict_window):
        self.data = data
        self.lookback_window = lookback_window
        self.predict_window = predict_window
        
        # Create samples
        self.samples = []
        for i in range(len(data) - lookback_window - predict_window + 1):
            sample = {
                'input': data[i:i+lookback_window],
                'target': data[i+lookback_window:i+lookback_window+predict_window],
                'index': i
            }
            self.samples.append(sample)
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        return self.samples[idx]

def load_qlib_data(config):
    """åŠ è½½qlibæ•°æ®è¿›è¡Œæ¨ç†"""
    print("ğŸ”„ åŠ è½½qlibæ•°æ®...")
    
    try:
        # åˆå§‹åŒ–qlib
        qlib.init(provider_uri=config['qlib_data_path'], region=REG_CN)
        
        # è·å–æ•°æ®
        from qlib.data import D
        
        instruments = D.instruments(market='csi300')
        fields = ['$open', '$high', '$low', '$close', '$volume', '$amount']
        
        # åŠ è½½æµ‹è¯•æ—¶é—´èŒƒå›´çš„æ•°æ®
        start_time = config['test_time_range'][0]
        end_time = config['test_time_range'][1]
        
        print(f"ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time}")
        print(f"ğŸ¢ è‚¡ç¥¨æ•°é‡: {len(instruments)}")
        
        data = D.features(instruments, fields, start_time=start_time, end_time=end_time, freq='day')
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œå½¢çŠ¶: {data.shape}")
        return data, instruments
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None, None

def run_inference_test(config, device):
    """è¿è¡Œæ¨ç†æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æ¨ç†æµ‹è¯•...")
    
    # åŠ è½½æ•°æ®
    data, instruments = load_qlib_data(config)
    if data is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    # åŠ è½½æ¨¡å‹
    try:
        print("ğŸ”„ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
        tokenizer = KronosTokenizer.from_pretrained(config['pretrained_tokenizer_path'])
        model = Kronos.from_pretrained(config['pretrained_predictor_path'])
        
        tokenizer.eval().to(device)
        model.eval().to(device)
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # è¿è¡Œæ¨ç†æµ‹è¯•
    try:
        print("ğŸ”„ æ‰§è¡Œæ¨ç†...")
        
        # é€‰æ‹©ä¸€å°éƒ¨åˆ†æ•°æ®è¿›è¡Œæµ‹è¯•
        test_data = data.head(1000)  # åªæµ‹è¯•å‰1000æ¡æ•°æ®
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = QlibInferenceDataset(
            test_data.values, 
            config['lookback_window'], 
            config['predict_window']
        )
        
        dataloader = DataLoader(dataset, batch_size=10, shuffle=False)
        
        predictions = []
        targets = []
        
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="æ¨ç†è¿›åº¦"):
                inputs = batch['input'].float().to(device)
                batch_targets = batch['target'].float()
                
                # æ‰§è¡Œæ¨ç†
                # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ¨¡å‹æ¥å£è°ƒæ•´
                try:
                    outputs = auto_regressive_inference(
                        model, tokenizer, inputs, 
                        config['predict_window'],
                        device=device
                    )
                    
                    predictions.append(outputs.cpu())
                    targets.append(batch_targets)
                    
                except Exception as e:
                    print(f"âš ï¸  æ‰¹æ¬¡æ¨ç†å¤±è´¥: {e}")
                    continue
        
        if predictions:
            predictions = torch.cat(predictions, dim=0)
            targets = torch.cat(targets, dim=0)
            
            print(f"âœ… æ¨ç†å®Œæˆ")
            print(f"ğŸ“Š é¢„æµ‹å½¢çŠ¶: {predictions.shape}")
            print(f"ğŸ“Š ç›®æ ‡å½¢çŠ¶: {targets.shape}")
            
            # è®¡ç®—ç®€å•çš„è¯„ä¼°æŒ‡æ ‡
            mse = torch.mean((predictions - targets) ** 2)
            print(f"ğŸ“ˆ å‡æ–¹è¯¯å·® (MSE): {mse.item():.6f}")
            
        else:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„æ¨ç†ç»“æœ")
            
    except Exception as e:
        print(f"âŒ æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Qlibæµ‹è¯•è„šæœ¬ä¿®å¤ç‰ˆæœ¬")
    parser.add_argument("--device", type=str, default="cpu", help="è®¾å¤‡ç±»å‹ (cpu/cuda:0)")
    parser.add_argument("--config", type=str, help="é…ç½®æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    print("ğŸš€ Qlibæµ‹è¯•è„šæœ¬ä¿®å¤ç‰ˆæœ¬")
    print(f"ğŸ’» ä½¿ç”¨è®¾å¤‡: {args.device}")
    
    # æ£€æŸ¥è®¾å¤‡å¯ç”¨æ€§
    if args.device.startswith('cuda') and not torch.cuda.is_available():
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
        device = torch.device('cpu')
    else:
        device = torch.device(args.device)
    
    # åŠ è½½é…ç½®
    try:
        config_instance = Config()
        config = config_instance.__dict__
        print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return 1
    
    # æ£€æŸ¥å¿…è¦çš„è·¯å¾„
    if not os.path.exists(config['qlib_data_path']):
        print(f"âŒ Qlibæ•°æ®è·¯å¾„ä¸å­˜åœ¨: {config['qlib_data_path']}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†è„šæœ¬")
        return 1
    
    # è¿è¡Œæµ‹è¯•
    try:
        run_inference_test(config, device)
        print("ğŸ‰ æµ‹è¯•å®Œæˆ!")
        return 0
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)