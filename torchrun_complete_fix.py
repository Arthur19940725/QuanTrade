#!/usr/bin/env python
"""
torchrunå®Œæ•´ä¿®å¤æ–¹æ¡ˆ
è§£å†³Windowsä¸‹çš„libuvé—®é¢˜ï¼Œå¹¶å¤„ç†è®­ç»ƒæµç¨‹
"""
import os
import sys
import argparse

def setup_training_environment():
    """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
    # ç¦ç”¨libuv
    os.environ["USE_LIBUV"] = "0"
    os.environ["WORLD_SIZE"] = "1"
    os.environ["RANK"] = "0"
    os.environ["LOCAL_RANK"] = "0"
    os.environ["MASTER_ADDR"] = "localhost"
    os.environ["MASTER_PORT"] = "12355"
    
    # æ·»åŠ è·¯å¾„
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    sys.path.append(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'finetune'))

def train_tokenizer_first():
    """å…ˆè®­ç»ƒåˆ†è¯å™¨"""
    print("ğŸ”§ æ­¥éª¤1: è®­ç»ƒåˆ†è¯å™¨")
    try:
        from train_tokenizer import main as train_tokenizer_main
        from config import Config
        
        config_instance = Config()
        config = config_instance.__dict__
        
        print("âœ… å¼€å§‹è®­ç»ƒåˆ†è¯å™¨...")
        train_tokenizer_main(config)
        print("âœ… åˆ†è¯å™¨è®­ç»ƒå®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ åˆ†è¯å™¨è®­ç»ƒå¤±è´¥: {e}")
        return False

def train_predictor():
    """è®­ç»ƒé¢„æµ‹å™¨"""
    print("ğŸ”§ æ­¥éª¤2: è®­ç»ƒé¢„æµ‹å™¨")
    try:
        from train_predictor import main as train_predictor_main
        from config import Config
        
        config_instance = Config()
        config = config_instance.__dict__
        
        # ä¿®æ”¹é…ç½®ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„åˆ†è¯å™¨è€Œä¸æ˜¯å¾®è°ƒçš„
        if not os.path.exists(config['finetuned_tokenizer_path']):
            print("âš ï¸  å¾®è°ƒåˆ†è¯å™¨ä¸å­˜åœ¨ï¼Œä½¿ç”¨é¢„è®­ç»ƒåˆ†è¯å™¨")
            config['finetuned_tokenizer_path'] = config['pretrained_tokenizer_path']
        
        print("âœ… å¼€å§‹è®­ç»ƒé¢„æµ‹å™¨...")
        train_predictor_main(config)
        print("âœ… é¢„æµ‹å™¨è®­ç»ƒå®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ é¢„æµ‹å™¨è®­ç»ƒå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Kronosè®­ç»ƒå®Œæ•´æ–¹æ¡ˆ")
    parser.add_argument("--standalone", action="store_true", help="å•æœºæ¨¡å¼")
    parser.add_argument("--nproc_per_node", type=int, default=1, help="æ¯ä¸ªèŠ‚ç‚¹çš„è¿›ç¨‹æ•°")
    parser.add_argument("--train-tokenizer", action="store_true", help="å…ˆè®­ç»ƒåˆ†è¯å™¨")
    parser.add_argument("--train-predictor", action="store_true", help="è®­ç»ƒé¢„æµ‹å™¨")
    parser.add_argument("--train-all", action="store_true", help="è®­ç»ƒæ‰€æœ‰ç»„ä»¶")
    parser.add_argument("script", nargs="?", help="è¦æ‰§è¡Œçš„è„šæœ¬")
    
    args = parser.parse_args()
    
    print("ğŸš€ Kronosè®­ç»ƒå®Œæ•´æ–¹æ¡ˆ")
    print("ğŸ“‹ è§£å†³Windowsä¸‹torchrun libuvé—®é¢˜")
    
    # è®¾ç½®ç¯å¢ƒ
    setup_training_environment()
    
    success = True
    
    if args.train_all:
        print("ğŸƒâ€â™‚ï¸ å®Œæ•´è®­ç»ƒæµç¨‹ (åˆ†è¯å™¨ + é¢„æµ‹å™¨)")
        success &= train_tokenizer_first()
        if success:
            success &= train_predictor()
    elif args.train_tokenizer:
        success &= train_tokenizer_first()
    elif args.train_predictor or (args.script and "train_predictor" in args.script):
        success &= train_predictor()
    elif args.script and "train_tokenizer" in args.script:
        success &= train_tokenizer_first()
    else:
        print("âŒ è¯·æŒ‡å®šè®­ç»ƒä»»åŠ¡:")
        print("   --train-all: è®­ç»ƒåˆ†è¯å™¨å’Œé¢„æµ‹å™¨")
        print("   --train-tokenizer: åªè®­ç»ƒåˆ†è¯å™¨") 
        print("   --train-predictor: åªè®­ç»ƒé¢„æµ‹å™¨")
        print("   æˆ–è€…ç›´æ¥æŒ‡å®šè„šæœ¬è·¯å¾„")
        return 1
    
    if success:
        print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
        return 0
    else:
        print("âŒ è®­ç»ƒå¤±è´¥!")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)