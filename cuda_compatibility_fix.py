#!/usr/bin/env python
"""
CUDAå…¼å®¹æ€§é—®é¢˜å®Œæ•´è§£å†³æ–¹æ¡ˆ
ä¸“é—¨è§£å†³RTX 5060 Tiç­‰æ–°GPUçš„PyTorchå…¼å®¹æ€§é—®é¢˜
"""
import os
import sys
import subprocess
import argparse

def check_pytorch_cuda_compatibility():
    """æ£€æŸ¥PyTorchå’ŒCUDAçš„å…¼å®¹æ€§"""
    print("ğŸ” æ£€æŸ¥PyTorchå’ŒCUDAå…¼å®¹æ€§...")
    
    try:
        import torch
        print(f"ğŸ“¦ PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"ğŸ”§ CUDAç‰ˆæœ¬: {torch.version.cuda}")
        
        if torch.cuda.is_available():
            print(f"ğŸ–¥ï¸  GPUæ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_capability = torch.cuda.get_device_capability(i)
                sm_version = f"sm_{gpu_capability[0]}{gpu_capability[1]}"
                print(f"   GPU {i}: {gpu_name} (è®¡ç®—èƒ½åŠ›: {sm_version})")
                
                # æ£€æŸ¥å…¼å®¹æ€§
                if gpu_capability[0] >= 12:  # sm_120åŠä»¥ä¸Š
                    print(f"âš ï¸  {gpu_name} ä½¿ç”¨æ–°æ¶æ„ {sm_version}")
                    print("   å½“å‰PyTorchç‰ˆæœ¬å¯èƒ½ä¸æ”¯æŒæ­¤æ¶æ„")
                    return False, f"GPUæ¶æ„ {sm_version} ä¸å…¼å®¹"
            
            return True, "CUDAå…¼å®¹"
        else:
            return False, "CUDAä¸å¯ç”¨"
            
    except ImportError:
        return False, "PyTorchæœªå®‰è£…"

def get_pytorch_upgrade_recommendation():
    """è·å–PyTorchå‡çº§å»ºè®®"""
    print("\nğŸ’¡ PyTorchå‡çº§å»ºè®®:")
    print("="*50)
    
    print("ğŸ¯ é’ˆå¯¹RTX 5060 Ti (sm_120)çš„è§£å†³æ–¹æ¡ˆ:")
    print("\n1. å‡çº§åˆ°æ”¯æŒæ–°æ¶æ„çš„PyTorchç‰ˆæœ¬:")
    print("   pip install torch>=2.2.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    
    print("\n2. æˆ–è€…ä½¿ç”¨PyTorch nightlyç‰ˆæœ¬:")
    print("   pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu121")
    
    print("\n3. å¦‚æœå‡çº§å›°éš¾ï¼Œå¼ºåˆ¶ä½¿ç”¨CPU:")
    print("   export CUDA_VISIBLE_DEVICES=\"\"")
    print("   æˆ–åœ¨Pythonä¸­: os.environ['CUDA_VISIBLE_DEVICES'] = ''")
    
    print("\n4. æ£€æŸ¥NVIDIAé©±åŠ¨ç‰ˆæœ¬:")
    print("   nvidia-smi")
    print("   ç¡®ä¿é©±åŠ¨ç‰ˆæœ¬æ”¯æŒCUDA 12.1+")

def create_cpu_only_script():
    """åˆ›å»ºå¼ºåˆ¶CPUè¿è¡Œçš„è„šæœ¬"""
    cpu_script = """#!/usr/bin/env python
import os
# å¼ºåˆ¶ä½¿ç”¨CPUï¼Œç¦ç”¨CUDA
os.environ['CUDA_VISIBLE_DEVICES'] = ''

# å¯¼å…¥å…¶ä»–æ¨¡å—
import sys
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir) if 'finetune' in current_dir else current_dir
finetune_dir = os.path.join(project_root, 'finetune')
sys.path.insert(0, project_root)
sys.path.insert(0, finetune_dir)

# è¿è¡ŒCPUç‰ˆæœ¬çš„qlibæµ‹è¯•
if __name__ == "__main__":
    print("ğŸš€ å¼ºåˆ¶CPUæ¨¡å¼è¿è¡Œ")
    print("ğŸ’» å·²ç¦ç”¨CUDAï¼Œä½¿ç”¨CPUè¿›è¡Œæ¨ç†")
    
    # å¯¼å…¥å¹¶è¿è¡Œæ™ºèƒ½è®¾å¤‡ç‰ˆæœ¬
    try:
        from qlib_test_smart_device import main
        import argparse
        
        # æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°
        sys.argv = ['qlib_test_cpu_only.py', '--device', 'cpu']
        main()
    except ImportError:
        print("âŒ è¯·ç¡®ä¿qlib_test_smart_device.pyå­˜åœ¨")
"""
    
    with open('qlib_test_cpu_only.py', 'w', encoding='utf-8') as f:
        f.write(cpu_script)
    
    print("âœ… åˆ›å»ºäº†å¼ºåˆ¶CPUè¿è¡Œè„šæœ¬: qlib_test_cpu_only.py")

def create_pytorch_upgrade_script():
    """åˆ›å»ºPyTorchå‡çº§è„šæœ¬"""
    upgrade_script = """#!/usr/bin/env python
import subprocess
import sys

def upgrade_pytorch():
    print("ğŸš€ å¼€å§‹å‡çº§PyTorchä»¥æ”¯æŒRTX 5060 Ti...")
    
    commands = [
        # å¸è½½æ—§ç‰ˆæœ¬
        [sys.executable, "-m", "pip", "uninstall", "torch", "torchvision", "torchaudio", "-y"],
        # å®‰è£…æ–°ç‰ˆæœ¬
        [sys.executable, "-m", "pip", "install", "torch>=2.2.0", "torchvision", "torchaudio", 
         "--index-url", "https://download.pytorch.org/whl/cu121"]
    ]
    
    for cmd in commands:
        print(f"æ‰§è¡Œ: {' '.join(cmd)}")
        try:
            subprocess.run(cmd, check=True)
        except subprocess.CalledProcessError as e:
            print(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    print("âœ… PyTorchå‡çº§å®Œæˆ!")
    return True

if __name__ == "__main__":
    upgrade_pytorch()
"""
    
    with open('upgrade_pytorch.py', 'w', encoding='utf-8') as f:
        f.write(upgrade_script)
    
    print("âœ… åˆ›å»ºäº†PyTorchå‡çº§è„šæœ¬: upgrade_pytorch.py")

def run_cpu_fallback_test():
    """è¿è¡ŒCPUå›é€€æµ‹è¯•"""
    print("\nğŸ§ª è¿è¡ŒCPUå›é€€æµ‹è¯•...")
    
    try:
        # è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ä½¿ç”¨CPU
        env = os.environ.copy()
        env['CUDA_VISIBLE_DEVICES'] = ''
        
        # è¿è¡Œæ™ºèƒ½è®¾å¤‡æµ‹è¯•
        result = subprocess.run([
            sys.executable, 'qlib_test_smart_device.py', '--device', 'cpu'
        ], env=env, capture_output=True, text=True, timeout=60)
        
        if result.returncode == 0:
            print("âœ… CPUå›é€€æµ‹è¯•æˆåŠŸ")
            return True
        else:
            print(f"âŒ CPUå›é€€æµ‹è¯•å¤±è´¥: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print("â° æµ‹è¯•è¶…æ—¶ï¼Œä½†è¿™é€šå¸¸è¡¨ç¤ºæ¨¡å‹æ­£åœ¨è¿è¡Œ")
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="CUDAå…¼å®¹æ€§é—®é¢˜è§£å†³æ–¹æ¡ˆ")
    parser.add_argument("--check", action="store_true", help="æ£€æŸ¥å…¼å®¹æ€§")
    parser.add_argument("--create-scripts", action="store_true", help="åˆ›å»ºè§£å†³æ–¹æ¡ˆè„šæœ¬")
    parser.add_argument("--test-cpu", action="store_true", help="æµ‹è¯•CPUå›é€€")
    parser.add_argument("--all", action="store_true", help="è¿è¡Œæ‰€æœ‰æ“ä½œ")
    
    args = parser.parse_args()
    
    print("ğŸš€ CUDAå…¼å®¹æ€§é—®é¢˜è§£å†³æ–¹æ¡ˆ")
    print("ğŸ¯ ä¸“é—¨è§£å†³RTX 5060 Tiç­‰æ–°GPUçš„PyTorchå…¼å®¹æ€§é—®é¢˜")
    print("="*60)
    
    if args.all or args.check:
        # æ£€æŸ¥å…¼å®¹æ€§
        compatible, reason = check_pytorch_cuda_compatibility()
        print(f"\nğŸ“Š å…¼å®¹æ€§æ£€æŸ¥ç»“æœ: {reason}")
        
        if not compatible:
            get_pytorch_upgrade_recommendation()
    
    if args.all or args.create_scripts:
        # åˆ›å»ºè§£å†³æ–¹æ¡ˆè„šæœ¬
        print("\nğŸ› ï¸  åˆ›å»ºè§£å†³æ–¹æ¡ˆè„šæœ¬...")
        create_cpu_only_script()
        create_pytorch_upgrade_script()
    
    if args.all or args.test_cpu:
        # æµ‹è¯•CPUå›é€€
        cpu_success = run_cpu_fallback_test()
    
    print("\n" + "="*60)
    print("ğŸ“‹ è§£å†³æ–¹æ¡ˆæ€»ç»“:")
    print("="*60)
    
    print("\nğŸ¯ ç«‹å³å¯ç”¨çš„è§£å†³æ–¹æ¡ˆ:")
    print("1. è¿è¡ŒCPUç‰ˆæœ¬: python qlib_test_cpu_only.py")
    print("2. æ™ºèƒ½è®¾å¤‡ç‰ˆæœ¬: python qlib_test_smart_device.py --device cpu")
    
    print("\nğŸ”§ é•¿æœŸè§£å†³æ–¹æ¡ˆ:")
    print("1. å‡çº§PyTorch: python upgrade_pytorch.py")
    print("2. æ›´æ–°NVIDIAé©±åŠ¨åˆ°æœ€æ–°ç‰ˆæœ¬")
    print("3. è€ƒè™‘ä½¿ç”¨PyTorch nightlyç‰ˆæœ¬")
    
    print("\nğŸ’¡ æ¨èåšæ³•:")
    print("- å¯¹äºRTX 5060 Tiç”¨æˆ·ï¼Œå»ºè®®å…ˆä½¿ç”¨CPUç‰ˆæœ¬")
    print("- ç­‰å¾…PyTorchå®˜æ–¹æ”¯æŒæ–°GPUæ¶æ„")
    print("- æˆ–å‡çº§åˆ°æ”¯æŒsm_120çš„PyTorchç‰ˆæœ¬")
    
    print("\nğŸ‰ ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨CPUæ¨¡å¼æ­£å¸¸è¿è¡ŒKronos!")

if __name__ == "__main__":
    main()